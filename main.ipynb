{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a1e9cdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5dbca182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the datasets\n",
    "clean_dataset = np.loadtxt('Dataset/clean_dataset.txt')\n",
    "noisy_dataset = np.loadtxt('Dataset/noisy_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a74bec86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(clean_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "68a0d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(noisy_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c657f244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-61. -60. -68. -62. -77. -90. -80.   1.]\n",
      " [-63. -65. -60. -63. -77. -81. -87.   1.]]\n"
     ]
    }
   ],
   "source": [
    "print(clean_dataset[1:5][2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a03f2f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clean_dataset[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "707a30c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[500 500 500 500]\n"
     ]
    }
   ],
   "source": [
    "nique, counts = np.unique(clean_dataset[:,-1], return_counts=True)\n",
    "# result = dict(zip(clean_dataset, counts))\n",
    "print(len(nique))\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "59a3d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder function to calculate entropy\n",
    "def cal_entropy(dataset):\n",
    "\n",
    "    nique, counts = np.unique(dataset[:,-1], return_counts=True)\n",
    "\n",
    "    pk_values = []\n",
    "\n",
    "    # calculating pk values\n",
    "    for k in range(len(nique)):\n",
    "        pk = counts[k]/len(dataset[:, -1])\n",
    "        pk_values.append(pk)\n",
    "\n",
    "    entropy = 0\n",
    "    # calculating entropy based on pk values\n",
    "    for pk in pk_values:\n",
    "        entropy += (pk * np.log2(pk))\n",
    "\n",
    "    return -1 * entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "30943eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the best split feature and value\n",
    "# We will iterate through all possible split points\n",
    "def find_split(dataset):\n",
    "\n",
    "    # Initialisation\n",
    "    best_info_gain = -9999\n",
    "    best_feature_index = None\n",
    "    best_feature_value = None\n",
    "\n",
    "    best_left_data = []\n",
    "    best_right_data = []\n",
    "\n",
    "    best_value = None\n",
    "\n",
    "    entropy_complete_dataset = cal_entropy(dataset)\n",
    "\n",
    "    # Loop through all features\n",
    "    for feature_index in range(dataset.shape[1]-1):\n",
    "        # Get unique feature values\n",
    "        unique_feature_values = np.unique(dataset[:,feature_index])\n",
    "\n",
    "        # Find all potential split points (midpoint between the values)\n",
    "        potential_splits = []\n",
    "\n",
    "        for i in range(len(unique_feature_values)-1):\n",
    "            current_value = unique_feature_values[i]\n",
    "            next_value = unique_feature_values[i+1]\n",
    "\n",
    "            mid_value = (current_value+next_value)/2\n",
    "\n",
    "            potential_splits.append(mid_value)\n",
    "\n",
    "        for split_value in potential_splits:\n",
    "            left_dataset_list = []\n",
    "            right_dataset_list = []\n",
    "\n",
    "            for row in dataset:\n",
    "                if row[feature_index] <= split_value:\n",
    "                    left_dataset_list.append(row)\n",
    "                else:\n",
    "                    right_dataset_list.append(row)\n",
    "            \n",
    "            left_dataset = np.array(left_dataset_list)\n",
    "            right_dataset = np.array(right_dataset_list)\n",
    "\n",
    "            prob_left = len(left_dataset) / len(dataset)\n",
    "            prob_right = len(right_dataset) / len(dataset)\n",
    "\n",
    "            information_gain = entropy_complete_dataset - (prob_left * cal_entropy(left_dataset) + (prob_right * cal_entropy(right_dataset)))\n",
    " \n",
    "            if information_gain > best_info_gain:\n",
    "                best_info_gain = information_gain\n",
    "                best_feature_index = feature_index\n",
    "                \n",
    "                best_left_data = left_dataset\n",
    "                best_right_data = right_dataset\n",
    "\n",
    "                best_value = split_value\n",
    "\n",
    "    return best_info_gain, best_feature_index, best_value, best_left_data, best_right_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "d77e70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9709505944546686\n"
     ]
    }
   ],
   "source": [
    "print(cal_entropy(np.array([[1],[1],[1],[2],[2],[3],[3],[3],[4],[4]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "1c909372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(cal_entropy(np.array([[2],[2],[2],[2],[2]])) == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "87e445e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our node class\n",
    "class Node:\n",
    "  def __init__(self, left = None, right = None, splitValue = None, attributeIndex = None,\n",
    "   isLeaf = False, prediction = None) -> None:\n",
    "    self.left = left\n",
    "    self.right = right\n",
    "    self.splitValue = splitValue\n",
    "    self.attributeIndex = attributeIndex\n",
    "    self.isLeaf = isLeaf\n",
    "    self.prediction = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bb98e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_learning(dataset, depth):\n",
    "\n",
    "    \n",
    "    \n",
    "    # if cal_entropy(dataset) == 0:\n",
    "    #     nique, counts = np.unique(dataset[:,-1], return_counts=True)\n",
    "    #     leafNode = Node(isLeaf=True, prediction=nique)\n",
    "    #     # print(\"LEAFNODE:  \", \"++++\", counts[0], \"----\", nique)\n",
    "    #     return leafNode, depth\n",
    "    \n",
    "    unique_labels = np.unique(dataset[:,-1])\n",
    "    if len(unique_labels)==1:\n",
    "        leafNode = Node(isLeaf=True, prediction=unique_labels[0])\n",
    "        return leafNode, depth\n",
    "\n",
    "    \n",
    "    best_info_gain, best_feature_index, best_value, left_data, right_data = find_split(dataset)\n",
    "\n",
    "    # Best feature index \n",
    "    # best info gain\n",
    "    # best feature value\n",
    "    node = Node(splitValue=best_value,\n",
    "                attributeIndex=best_feature_index)\n",
    "    node.left, l_depth = decision_tree_learning(left_data, depth + 1)\n",
    "    node.right, r_depth = decision_tree_learning(right_data, depth + 1)\n",
    "\n",
    "    return (node, max(l_depth, r_depth))\n",
    "\n",
    "\n",
    "\n",
    "# # result = dict(zip(clean_dataset, counts))\n",
    "# print(len(nique))\n",
    "# print(counts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8fe31943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'left': <__main__.Node object at 0x108432d90>, 'right': <__main__.Node object at 0x1085f15b0>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "18\n",
      "2.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "node, depth = decision_tree_learning(noisy_dataset, 0)\n",
    "\n",
    "print(vars(node))\n",
    "print(depth)\n",
    "\n",
    "print(get_prediction(node, clean_dataset[0]))\n",
    "print(clean_dataset[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2dd72afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to shuffle data indices and split values\n",
    "def kfold_datasets_generator(dataset):\n",
    "\n",
    "    working_data = dataset.copy()\n",
    "    print(working_data.shape)\n",
    "    # print(working_data[:5])\n",
    "    # shuffling the rows\n",
    "    np.random.shuffle(working_data)\n",
    "    # print(working_data[:5])\n",
    "\n",
    "    split_datasets = np.split(working_data, 10)\n",
    "    print(len(split_datasets))\n",
    "    print(split_datasets[0].shape)\n",
    "\n",
    "    # print(sub_array[0][:5])\n",
    "    # Okay, now we have 10 datasets. We need to focus on training the tree on the first 9 and evaluate on the last 1\n",
    "\n",
    "    l = []\n",
    "    for i in range(len(split_datasets)):\n",
    "        # The ith set will be the testing set, the rest will be the training set\n",
    "        testing_set = split_datasets[i]\n",
    "        training_set = split_datasets[:i] + split_datasets[i + 1:]\n",
    "\n",
    "        training_set = np.concatenate((training_set), axis = 0)\n",
    "\n",
    "        d = {'testing': testing_set, 'training': training_set}\n",
    "        l.append(d)\n",
    "        # d[\"testing\": split_datasets[i]]\n",
    "    \n",
    "    # print((l[i]['testing'].shape, l[i]['training'].shape) for i in range(len(l)))\n",
    "    # for i in range(len(l)):\n",
    "    #     print(l[i]['testing'].shape, l[i]['training'].shape)\n",
    "    #     # print()\n",
    "    \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4d546e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(node: Node, input):\n",
    "\n",
    "    ## TODO: Add a loop to loop through every row in the input set\n",
    "    val = node.splitValue\n",
    "    index = node.attributeIndex\n",
    "    if node.isLeaf:\n",
    "        # print(\"NOde prediction = \", node.prediction)\n",
    "        return node.prediction\n",
    "    if input[index] <= val:\n",
    "        # print(\"YES\")\n",
    "        return get_prediction(node.left, input)\n",
    "    else:\n",
    "        # print(\"NO\")\n",
    "        return get_prediction(node.right, input)\n",
    "    # print(input.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "ad4b3bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_evaluator(datasets):\n",
    "    all_fold_accuracies = []\n",
    "    \n",
    "    for i in datasets:\n",
    "        node, depth = decision_tree_learning(i['training'], 0)\n",
    "        print(vars(node))\n",
    "        print(depth)\n",
    "\n",
    "        confusion_matrix = [[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0],[0, 0, 0, 0]]\n",
    "\n",
    "\n",
    "        for j in range(len(i['testing'])):\n",
    "            predicted = get_prediction(node, i['testing'][j])\n",
    "            actual = i['testing'][j][-1]\n",
    "            predicted.astype(np.int64)\n",
    "            predicted = predicted.astype(np.int64)\n",
    "            actual = actual.astype(np.int64)\n",
    "            confusion_matrix[predicted - 1][actual - 1] += 1\n",
    "        confusion_matrix = np.array(confusion_matrix)\n",
    "        print(confusion_matrix)\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        # --- Integrated Statistics Calculation ---\n",
    "        \n",
    "        print(\"--- Per-Class Statistics ---\")\n",
    "        \n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "\n",
    "        for k in range(4): # Use 'k' to avoid shadowing the outer 'i'\n",
    "            class_name = f\"Class {k+1}\"\n",
    "\n",
    "            # True Positives: Correctly predicted for this class\n",
    "            true_positives = confusion_matrix[k, k]\n",
    "            \n",
    "            # False Positives: Predicted as this class, but was actually another\n",
    "            # Sum of row 'k', minus the TP\n",
    "            false_positives = np.sum(confusion_matrix[k, :]) - true_positives\n",
    "            \n",
    "            # False Negatives: Actually this class, but predicted as another\n",
    "            # Sum of column 'k', minus the TP\n",
    "            false_negatives = np.sum(confusion_matrix[:, k]) - true_positives\n",
    "\n",
    "            # --- Calculate Precision ---\n",
    "            # TP / (TP + FP)\n",
    "            precision_denominator = (true_positives + false_positives)\n",
    "            if precision_denominator == 0:\n",
    "                precision = 0.0\n",
    "            else:\n",
    "                precision = true_positives / precision_denominator\n",
    "            \n",
    "            precision_scores.append(precision)\n",
    "\n",
    "            # --- Calculate Recall ---\n",
    "            # TP / (TP + FN)\n",
    "            recall_denominator = (true_positives + false_negatives)\n",
    "            if recall_denominator == 0:\n",
    "                recall = 0.0\n",
    "            else:\n",
    "                recall = true_positives / recall_denominator\n",
    "            \n",
    "            recall_scores.append(recall)\n",
    "\n",
    "            print(f\"{class_name}:\")\n",
    "            print(f\"  True Positives:  {true_positives}\")\n",
    "            print(f\"  False Positives: {false_positives}\")\n",
    "            print(f\"  False Negatives: {false_negatives}\")\n",
    "            print(f\"  Precision:       {precision:.4f}\")\n",
    "            print(f\"  Recall:          {recall:.4f}\")\n",
    "\n",
    "        print(\"-\" * 30)\n",
    "        print(\"--- Overall Statistics (for this fold) ---\")\n",
    "        \n",
    "        # Overall Accuracy = (Sum of all correct) / (Total samples)\n",
    "        total_correct = np.trace(confusion_matrix) # Sum of the diagonal\n",
    "        total_samples = np.sum(confusion_matrix)\n",
    "        \n",
    "        if total_samples == 0:\n",
    "            overall_accuracy = 0.0\n",
    "        else:\n",
    "            overall_accuracy = total_correct / total_samples\n",
    "            \n",
    "        all_fold_accuracies.append(overall_accuracy)\n",
    "\n",
    "        print(f\"Overall Accuracy: {overall_accuracy:.4f}\")\n",
    "        print(f\"Average Precision: {np.mean(precision_scores):.4f}\")\n",
    "        print(f\"Average Recall: {np.mean(recall_scores):.4f}\")\n",
    "        print(\"=\" * 30 + \"\\n\")\n",
    "\n",
    "\n",
    "    print(\"--- Final K-Fold Summary ---\")\n",
    "    if len(all_fold_accuracies) > 0:\n",
    "        print(f\"Average Overall Accuracy across all folds: {np.mean(all_fold_accuracies):.4f}\")\n",
    "    else:\n",
    "        print(\"No datasets were processed.\")\n",
    "            \n",
    "\n",
    "\n",
    "        # get_predictions(node, depth, i['testing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6e8658f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 8)\n",
      "10\n",
      "(200, 8)\n",
      "{'left': <__main__.Node object at 0x1084fa850>, 'right': <__main__.Node object at 0x108cf3130>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "21\n",
      "[[57  5  2  2]\n",
      " [ 0 40  5  1]\n",
      " [ 3  5 36  2]\n",
      " [ 4  4  3 31]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  57\n",
      "  False Positives: 9\n",
      "  False Negatives: 7\n",
      "  Precision:       0.8636\n",
      "  Recall:          0.8906\n",
      "Class 2:\n",
      "  True Positives:  40\n",
      "  False Positives: 6\n",
      "  False Negatives: 14\n",
      "  Precision:       0.8696\n",
      "  Recall:          0.7407\n",
      "Class 3:\n",
      "  True Positives:  36\n",
      "  False Positives: 10\n",
      "  False Negatives: 10\n",
      "  Precision:       0.7826\n",
      "  Recall:          0.7826\n",
      "Class 4:\n",
      "  True Positives:  31\n",
      "  False Positives: 11\n",
      "  False Negatives: 5\n",
      "  Precision:       0.7381\n",
      "  Recall:          0.8611\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.8200\n",
      "Average Precision: 0.8135\n",
      "Average Recall: 0.8188\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108bec730>, 'right': <__main__.Node object at 0x108cc9d60>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "19\n",
      "[[46  2  3  4]\n",
      " [ 1 33  4  5]\n",
      " [ 2  1 31  6]\n",
      " [ 6  3  2 51]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  46\n",
      "  False Positives: 9\n",
      "  False Negatives: 9\n",
      "  Precision:       0.8364\n",
      "  Recall:          0.8364\n",
      "Class 2:\n",
      "  True Positives:  33\n",
      "  False Positives: 10\n",
      "  False Negatives: 6\n",
      "  Precision:       0.7674\n",
      "  Recall:          0.8462\n",
      "Class 3:\n",
      "  True Positives:  31\n",
      "  False Positives: 9\n",
      "  False Negatives: 9\n",
      "  Precision:       0.7750\n",
      "  Recall:          0.7750\n",
      "Class 4:\n",
      "  True Positives:  51\n",
      "  False Positives: 11\n",
      "  False Negatives: 15\n",
      "  Precision:       0.8226\n",
      "  Recall:          0.7727\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.8050\n",
      "Average Precision: 0.8003\n",
      "Average Recall: 0.8076\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108bec4c0>, 'right': <__main__.Node object at 0x108bdad60>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "17\n",
      "[[42  3  3  1]\n",
      " [ 7 38  4  4]\n",
      " [ 5  7 37  3]\n",
      " [ 6  2  2 36]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  42\n",
      "  False Positives: 7\n",
      "  False Negatives: 18\n",
      "  Precision:       0.8571\n",
      "  Recall:          0.7000\n",
      "Class 2:\n",
      "  True Positives:  38\n",
      "  False Positives: 15\n",
      "  False Negatives: 12\n",
      "  Precision:       0.7170\n",
      "  Recall:          0.7600\n",
      "Class 3:\n",
      "  True Positives:  37\n",
      "  False Positives: 15\n",
      "  False Negatives: 9\n",
      "  Precision:       0.7115\n",
      "  Recall:          0.8043\n",
      "Class 4:\n",
      "  True Positives:  36\n",
      "  False Positives: 10\n",
      "  False Negatives: 8\n",
      "  Precision:       0.7826\n",
      "  Recall:          0.8182\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.7650\n",
      "Average Precision: 0.7671\n",
      "Average Recall: 0.7706\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108cbd130>, 'right': <__main__.Node object at 0x108bea7f0>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "19\n",
      "[[31  6  4  3]\n",
      " [ 2 48  6  3]\n",
      " [ 2  1 31  4]\n",
      " [ 6  5  5 43]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  31\n",
      "  False Positives: 13\n",
      "  False Negatives: 10\n",
      "  Precision:       0.7045\n",
      "  Recall:          0.7561\n",
      "Class 2:\n",
      "  True Positives:  48\n",
      "  False Positives: 11\n",
      "  False Negatives: 12\n",
      "  Precision:       0.8136\n",
      "  Recall:          0.8000\n",
      "Class 3:\n",
      "  True Positives:  31\n",
      "  False Positives: 7\n",
      "  False Negatives: 15\n",
      "  Precision:       0.8158\n",
      "  Recall:          0.6739\n",
      "Class 4:\n",
      "  True Positives:  43\n",
      "  False Positives: 16\n",
      "  False Negatives: 10\n",
      "  Precision:       0.7288\n",
      "  Recall:          0.8113\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.7650\n",
      "Average Precision: 0.7657\n",
      "Average Recall: 0.7603\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108cd95e0>, 'right': <__main__.Node object at 0x108cd3ac0>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "19\n",
      "[[33  2  2  6]\n",
      " [ 2 57  3  4]\n",
      " [ 5  4 34  3]\n",
      " [ 2  1  6 36]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  33\n",
      "  False Positives: 10\n",
      "  False Negatives: 9\n",
      "  Precision:       0.7674\n",
      "  Recall:          0.7857\n",
      "Class 2:\n",
      "  True Positives:  57\n",
      "  False Positives: 9\n",
      "  False Negatives: 7\n",
      "  Precision:       0.8636\n",
      "  Recall:          0.8906\n",
      "Class 3:\n",
      "  True Positives:  34\n",
      "  False Positives: 12\n",
      "  False Negatives: 11\n",
      "  Precision:       0.7391\n",
      "  Recall:          0.7556\n",
      "Class 4:\n",
      "  True Positives:  36\n",
      "  False Positives: 9\n",
      "  False Negatives: 13\n",
      "  Precision:       0.8000\n",
      "  Recall:          0.7347\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.8000\n",
      "Average Precision: 0.7926\n",
      "Average Recall: 0.7916\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108cd3310>, 'right': <__main__.Node object at 0x108bdb160>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "20\n",
      "[[35  1  4  6]\n",
      " [ 5 40  3  1]\n",
      " [ 4  5 41  3]\n",
      " [ 1  1  6 44]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  35\n",
      "  False Positives: 11\n",
      "  False Negatives: 10\n",
      "  Precision:       0.7609\n",
      "  Recall:          0.7778\n",
      "Class 2:\n",
      "  True Positives:  40\n",
      "  False Positives: 9\n",
      "  False Negatives: 7\n",
      "  Precision:       0.8163\n",
      "  Recall:          0.8511\n",
      "Class 3:\n",
      "  True Positives:  41\n",
      "  False Positives: 12\n",
      "  False Negatives: 13\n",
      "  Precision:       0.7736\n",
      "  Recall:          0.7593\n",
      "Class 4:\n",
      "  True Positives:  44\n",
      "  False Positives: 8\n",
      "  False Negatives: 10\n",
      "  Precision:       0.8462\n",
      "  Recall:          0.8148\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.8000\n",
      "Average Precision: 0.7992\n",
      "Average Recall: 0.8007\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108d09640>, 'right': <__main__.Node object at 0x108cbdd90>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "22\n",
      "[[38  3  3  3]\n",
      " [ 3 44  3  1]\n",
      " [ 3  3 43  5]\n",
      " [ 1  4  2 41]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  38\n",
      "  False Positives: 9\n",
      "  False Negatives: 7\n",
      "  Precision:       0.8085\n",
      "  Recall:          0.8444\n",
      "Class 2:\n",
      "  True Positives:  44\n",
      "  False Positives: 7\n",
      "  False Negatives: 10\n",
      "  Precision:       0.8627\n",
      "  Recall:          0.8148\n",
      "Class 3:\n",
      "  True Positives:  43\n",
      "  False Positives: 11\n",
      "  False Negatives: 8\n",
      "  Precision:       0.7963\n",
      "  Recall:          0.8431\n",
      "Class 4:\n",
      "  True Positives:  41\n",
      "  False Positives: 7\n",
      "  False Negatives: 9\n",
      "  Precision:       0.8542\n",
      "  Recall:          0.8200\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.8300\n",
      "Average Precision: 0.8304\n",
      "Average Recall: 0.8306\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108bea250>, 'right': <__main__.Node object at 0x108bda550>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "19\n",
      "[[40  2  5  3]\n",
      " [ 1 36  4  2]\n",
      " [ 0  4 57  1]\n",
      " [ 2  5  2 36]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  40\n",
      "  False Positives: 10\n",
      "  False Negatives: 3\n",
      "  Precision:       0.8000\n",
      "  Recall:          0.9302\n",
      "Class 2:\n",
      "  True Positives:  36\n",
      "  False Positives: 7\n",
      "  False Negatives: 11\n",
      "  Precision:       0.8372\n",
      "  Recall:          0.7660\n",
      "Class 3:\n",
      "  True Positives:  57\n",
      "  False Positives: 5\n",
      "  False Negatives: 11\n",
      "  Precision:       0.9194\n",
      "  Recall:          0.8382\n",
      "Class 4:\n",
      "  True Positives:  36\n",
      "  False Positives: 9\n",
      "  False Negatives: 6\n",
      "  Precision:       0.8000\n",
      "  Recall:          0.8571\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.8450\n",
      "Average Precision: 0.8391\n",
      "Average Recall: 0.8479\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108cfc370>, 'right': <__main__.Node object at 0x108c486a0>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "19\n",
      "[[33  3  3  7]\n",
      " [ 2 33  5  2]\n",
      " [ 3  4 46  4]\n",
      " [ 1  4  4 46]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  33\n",
      "  False Positives: 13\n",
      "  False Negatives: 6\n",
      "  Precision:       0.7174\n",
      "  Recall:          0.8462\n",
      "Class 2:\n",
      "  True Positives:  33\n",
      "  False Positives: 9\n",
      "  False Negatives: 11\n",
      "  Precision:       0.7857\n",
      "  Recall:          0.7500\n",
      "Class 3:\n",
      "  True Positives:  46\n",
      "  False Positives: 11\n",
      "  False Negatives: 12\n",
      "  Precision:       0.8070\n",
      "  Recall:          0.7931\n",
      "Class 4:\n",
      "  True Positives:  46\n",
      "  False Positives: 9\n",
      "  False Negatives: 13\n",
      "  Precision:       0.8364\n",
      "  Recall:          0.7797\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.7900\n",
      "Average Precision: 0.7866\n",
      "Average Recall: 0.7922\n",
      "==============================\n",
      "\n",
      "{'left': <__main__.Node object at 0x108cccd00>, 'right': <__main__.Node object at 0x108cfefd0>, 'splitValue': -54.5, 'attributeIndex': 0, 'isLeaf': False, 'prediction': None}\n",
      "16\n",
      "[[44  3  6  3]\n",
      " [ 2 30  5  9]\n",
      " [ 5  3 45  3]\n",
      " [ 5  2  5 30]]\n",
      "------------------------------\n",
      "--- Per-Class Statistics ---\n",
      "Class 1:\n",
      "  True Positives:  44\n",
      "  False Positives: 12\n",
      "  False Negatives: 12\n",
      "  Precision:       0.7857\n",
      "  Recall:          0.7857\n",
      "Class 2:\n",
      "  True Positives:  30\n",
      "  False Positives: 16\n",
      "  False Negatives: 8\n",
      "  Precision:       0.6522\n",
      "  Recall:          0.7895\n",
      "Class 3:\n",
      "  True Positives:  45\n",
      "  False Positives: 11\n",
      "  False Negatives: 16\n",
      "  Precision:       0.8036\n",
      "  Recall:          0.7377\n",
      "Class 4:\n",
      "  True Positives:  30\n",
      "  False Positives: 12\n",
      "  False Negatives: 15\n",
      "  Precision:       0.7143\n",
      "  Recall:          0.6667\n",
      "------------------------------\n",
      "--- Overall Statistics (for this fold) ---\n",
      "Overall Accuracy: 0.7450\n",
      "Average Precision: 0.7389\n",
      "Average Recall: 0.7449\n",
      "==============================\n",
      "\n",
      "--- Final K-Fold Summary ---\n",
      "Average Overall Accuracy across all folds: 0.7965\n"
     ]
    }
   ],
   "source": [
    "datasets = kfold_datasets_generator(noisy_dataset)\n",
    "kfold_evaluator(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff745e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 4, 5],\n",
       "       [6, 7, 8],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.arange(9).reshape((3, 3))\n",
    "print(arr)\n",
    "np.random.shuffle(arr)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c35ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4]\n",
      " [3 2 3 5]\n",
      " [4 2 3 4]\n",
      " [5 2 3 4]]\n",
      "==\n",
      "[[5]\n",
      " [6]]\n",
      "==\n",
      "[[4]\n",
      " [5]]\n",
      "==\n",
      "[[1]]\n",
      "==\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [6]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = np.array([[1, 2, 3, 4], [3, 2, 3, 5], [4, 2, 3, 4], [5, 2, 3, 4]])\n",
    "print(cf)\n",
    "print(\"==\")\n",
    "# cf[1:][0]\n",
    "print(np.add(cf[:1, [0]], cf[2:, [0]]))\n",
    "print(\"==\")\n",
    "print(cf[2:, [0]])\n",
    "print(\"==\")\n",
    "print(cf[:1, [0]])\n",
    "print(\"==\")\n",
    "np.add(cf[:1, [0]], cf[2:, [0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redditEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
